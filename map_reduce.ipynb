{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fa9c081d3524bb3f0791701dd1672cfa",
     "grade": false,
     "grade_id": "cell-b038e38b5e3072a9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# IST 718: Big Data Analytics\n",
    "\n",
    "- Professor: Daniel Acuna <deacuna@syr.edu>\n",
    "- TAs: Tong Zeng <tozeng@syr.edu>, Priya Matnani <psmatnan@syr.edu>\n",
    "\n",
    "## General instructions:\n",
    "\n",
    "- You are welcome to discuss the problems with your classmates but __you are not allowed to copy any of the answers either from your classmates or from the internet__\n",
    "- You can put the homework files anywhere you want in your http://notebook.acuna.io workspace but _do not change_ the file names. The TAs and the professor use these names to grade your homework.\n",
    "- Remove or comment out code that contain `raise NotImplementedError`. This is main to make the `assert` statement fail.\n",
    "- The tests shown in some cells (i.e., `assert` statements) might not be the only ones used by the professor. Think about cases where your code should run even if it passess all hidden cases.\n",
    "- Before downloading and submitting your work through Blackboard, remember to save and press `Validate` (or go to \n",
    "`Kernel`$\\rightarrow$`Restart and Run All`). \n",
    "- Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: MapReduce with Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code to create the Spark session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('map-reduce').getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this RDD will be used throughout this part of the homework\n",
    "gpa_rdd = sc.parallelize([\n",
    " ['2015', 'Fall', 'IST101', 1, 'A', 4],\n",
    " ['2015', 'Fall', 'IST195', 3, 'A', 4],\n",
    " ['2015', 'Fall', 'IST233', 3, 'B+', 3.3],\n",
    " ['2015', 'Fall', 'SOC101', 3, 'A-', 3.7],\n",
    " ['2015', 'Fall', 'MAT221', 3, 'C', 2],\n",
    " ['2016', 'Fall', 'IST346', 3, 'A', 4],\n",
    " ['2016', 'Fall', 'CHE111', 4, 'A-', 3.7],\n",
    " ['2016', 'Fall', 'PSY120', 3, 'B+', 3.3],\n",
    " ['2016', 'Fall', 'IST256', 3, 'A', 4],\n",
    " ['2016', 'Fall', 'ENG121', 3, 'B+', 3.3],\n",
    " ['2016', 'Spring', 'GEO110', 3, 'B+', 3.3],\n",
    " ['2016', 'Spring', 'MAT222', 3, 'A', 4],\n",
    " ['2016', 'Spring', 'SOC121', 3, 'C+', 2.3],\n",
    " ['2016', 'Spring', 'BIO240', 3, 'B-', 2.7]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.1 (10 pts) Cumulative GPA with MapReduce (25 pts)\n",
    "\n",
    "The cumulative GPA reported in any transcript is the average of the numerical score of a course weighted by the credits of such course. Construct a MapReduce job that takes the `gpa_rdd` RDD and returns the cumulative GPA *per season*. \n",
    "\n",
    "Each record in `gpa_rdd` contains:\n",
    "- The year\n",
    "- The season\n",
    "- The course code\n",
    "- The number of credits\n",
    "- The letter grade\n",
    "- The number grade\n",
    "\n",
    "**Hint:** In class, we discussed the MapReduce job for computing avereage. In this case, the key-value pairs will be similar but instead of counting the number of elements considered in the avarage so far, we need to count the credits. Clearly, the key needs to be the season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b9838d4d7ba5c693e77b11ccade70d0f",
     "grade": false,
     "grade_id": "cell-9cd285edff34dc29",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def map_weighted_gpa(record):\n",
    "    # YOUR CODE HERE\n",
    "    maped_rdd = [record[1],[record[5],record[3]]]\n",
    "    return maped_rdd\n",
    "    #raise NotImplementedError()\n",
    "\n",
    "def reduce_weighted_gpa(value1, value2):\n",
    "    # YOUR CODE HERE    \n",
    "    n = value1[0]*value1[1]+value2[0]*value2[1]\n",
    "    d = value1[1]+value2[1]\n",
    "    r = [n/d,d]\n",
    "    return r\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The map job should produce as key the season and value a tuple or list with the grade and credit.\n",
    "\n",
    "For example, the first element of the map of `gpa_rdd` should be\n",
    "\n",
    "```python\n",
    "gpa_rdd.\\\n",
    "    map(map_weighted_gpa).\\\n",
    "    first()\n",
    "```\n",
    "\n",
    "```python\n",
    "['Fall', [4, 1]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fall', [4, 1]]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpa_rdd.\\\n",
    "    map(map_weighted_gpa).\\\n",
    "    first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "139b781ec2bd7f803bea9c3571f9d07a",
     "grade": true,
     "grade_id": "cell-cb3fc3eeaf78b636",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "##### first result\n",
    "assert gpa_rdd.\\\n",
    "    map(map_weighted_gpa).\\\n",
    "    first() == ['Fall', [4, 1]]\n",
    "# the key should be a string\n",
    "assert gpa_rdd.map(map_weighted_gpa).map(lambda x: type(x[0])).distinct().count() == 1\n",
    "assert gpa_rdd.map(map_weighted_gpa).map(lambda x: type(x[0])).distinct().first() == str\n",
    "# all values should be of length 2\n",
    "assert gpa_rdd.map(map_weighted_gpa).map(lambda x: len(x[1])).distinct().count() == 1\n",
    "assert gpa_rdd.map(map_weighted_gpa).map(lambda x: len(x[1])).distinct().first() == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there should be two results in the map reduce because there are two semesters\n",
    "gpa_rdd.\\\n",
    "    map(map_weighted_gpa).\\\n",
    "    reduceByKey(reduce_weighted_gpa).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6387d11a00a4ff25515d867099bc62af",
     "grade": true,
     "grade_id": "cell-8076e4e7419738f4",
     "locked": true,
     "points": 15,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert (gpa_rdd.\\\n",
    "    map(map_weighted_gpa).\\\n",
    "    reduceByKey(reduce_weighted_gpa).collect() == \\\n",
    "    [('Spring', [3.0749999999999997, 12]), \n",
    "     ('Fall', [3.503448275862069, 29])]) or \\\n",
    "    (gpa_rdd.\\\n",
    "    map(map_weighted_gpa).\\\n",
    "    reduceByKey(reduce_weighted_gpa).collect() == \\\n",
    "    [('Fall', [3.503448275862069, 29]),\n",
    "     ('Spring', [3.0749999999999997, 12])])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
