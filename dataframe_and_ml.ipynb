{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c51f80b694da894627ba37be28c86055",
     "grade": false,
     "grade_id": "cell-b038e38b5e3072a9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# IST 718: Big Data Analytics\n",
    "\n",
    "- Professor: Daniel Acuna <deacuna@syr.edu>\n",
    "- TAs: Tong Zeng <tozeng@syr.edu>, Priya Matnani <psmatnan@syr.edu>\n",
    "\n",
    "## General instructions:\n",
    "\n",
    "- You are welcome to discuss the problems with your classmates but __you are not allowed to copy any part of your answers either from your classmates or from the internet__\n",
    "- You can put the homework files anywhere you want in your http://notebook.acuna.io workspace but _do not change_ the file names. The TAs and the professor use these names to grade your homework.\n",
    "- Remove or comment out code that contains `raise NotImplementedError`. This is mainly to make the `assert` statement fail if nothing is submitted.\n",
    "- The tests shown in some cells (i.e., `assert` statements) are used to grade your answers. **However, the professor and TAs will use __additional__ test for your answer. Think about cases where your code should run even if it passess all the tests you see.**\n",
    "- Before downloading and submitting your work through Blackboard, remember to save and press `Validate` (or go to \n",
    "`Kernel`$\\rightarrow$`Restart and Run All`). \n",
    "- Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the packages needed for this part\n",
    "# create spark and sparkcontext objects\n",
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "from pyspark.ml import feature\n",
    "from pyspark.ml import regression\n",
    "from pyspark.sql import functions as fn\n",
    "from pyspark.sql import Row\n",
    "from pyspark import sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warning: Use exclusively Spark. Do not use Pandas at all in this assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Dataframes and Spark ML\n",
    "\n",
    "In this section, you will learn to create dataframes from messy data and then perform simple regression on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is some mysterious process generating data, stored in `/datasets/host_server_requests`, with the following format:\n",
    "\n",
    "`feature1|feature2|...|featurem => outcome`\n",
    "\n",
    "`feature1` can be either \"HOST\" or \"SERVER\" and from feature $2$ through $m$ are floating point numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests_rdd = sc.textFile('/datasets/host_server_requests')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1:\n",
    "\n",
    "In this question, you will create a function `process_line` that receives a line from `/datasets/host_server_requests` and returns a `Row` object with the following columns: \n",
    "\n",
    "- You will codify the first feature as a column `f1` with a `1` if the source is `HOST` and `0` otherwise\n",
    "- You will create 7 other features that you assign to columns `f2`, `f3`, ..., through `f8`\n",
    "- Finally, you will assign the outcome to the column `label`\n",
    "- Remember to make all features of type `float`.\n",
    "\n",
    "For the following code:\n",
    "\n",
    "\n",
    "```python\n",
    "requests_rdd.map(process_line).take(10)\n",
    "```\n",
    "\n",
    "it should generate the following:\n",
    "\n",
    "```python\n",
    "[Row(f1=1.0, f2=2e-05, f3=0.80279, f4=-0.09174, f5=0.04041, f6=-0.22504, f7=-0.0504, f8=0.58149, label=163.877101489),\n",
    " Row(f1=1.0, f2=5e-05, f3=-0.00454, f4=-0.0211, f5=0.00174, f6=-0.11684, f7=0.19182, f8=-0.23745, label=-105.023368852),\n",
    " Row(f1=1.0, f2=0.00015, f3=-0.10437, f4=0.04869, f5=0.18333, f6=-0.21864, f7=0.27638, f8=-0.13441, label=-115.011801582),\n",
    " Row(f1=1.0, f2=-0.00015, f3=0.27118, f4=0.14526, f5=0.06101, f6=0.13401, f7=0.06237, f8=-0.74065, label=-122.623452696),\n",
    " Row(f1=1.0, f2=-6e-05, f3=0.1413, f4=0.12084, f5=0.05452, f6=0.09272, f7=0.2534, f8=-0.65331, label=-117.130523174),\n",
    " Row(f1=1.0, f2=-8e-05, f3=-0.41534, f4=-0.04205, f5=-0.00724, f6=-0.07463, f7=0.13273, f8=0.19112, label=-73.5775668047),\n",
    " Row(f1=1.0, f2=-8e-05, f3=-0.45937, f4=-0.23509, f5=-0.05679, f6=0.06077, f7=-0.49597, f8=-0.30668, label=-137.37933148),\n",
    " Row(f1=0.0, f2=2e-05, f3=-0.23465, f4=0.07345, f5=-0.07217, f6=-0.19256, f7=-0.14377, f8=-0.15183, label=-162.804738349),\n",
    " Row(f1=0.0, f2=-7e-05, f3=-0.10321, f4=0.27467, f5=0.04058, f6=-0.24541, f7=0.08631, f8=-0.2979, label=-212.111291232),\n",
    " Row(f1=1.0, f2=-7e-05, f3=-0.01039, f4=-0.00453, f5=-0.01352, f6=-0.05199, f7=-0.3772, f8=-0.19641, label=-91.5022329392)]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e7bfb1bab0ea9927c8e6f6fd39415b44",
     "grade": false,
     "grade_id": "cell-244fd5f7c0138b60",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def process_line(line):\n",
    "    # YOUR CODE HERE\n",
    "    parts = line.split('|')\n",
    "    if parts[0] == \"HOST\":\n",
    "        parts[0]=1\n",
    "    else:\n",
    "        parts[0]=0\n",
    "    subParts = parts[7].split('=>')\n",
    "    raw_data = Row(f1 = float(parts[0]),f2=float(parts[1]), f3=float(parts[2]), f4=float(parts[3]), f5=float(parts[4]), \\\n",
    "                    f6=float(parts[5]), f7=float(parts[6]), f8=float(subParts[0].strip()), label=float(subParts[1].strip()))\n",
    "    return raw_data\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(f1=0.0, f2=8e-05, f3=0.45592, f4=0.25362, f5=-0.12878, f6=-0.0693, f7=-0.1474, f8=-0.53736, label=-106.947151761),\n",
       " Row(f1=0.0, f2=-1e-05, f3=0.10405, f4=-0.17047, f5=0.10127, f6=0.13776, f7=0.66619, f8=0.32221, label=127.061566761),\n",
       " Row(f1=1.0, f2=-1e-05, f3=-0.72394, f4=0.31161, f5=0.06975, f6=0.0086, f7=-0.44817, f8=-0.22976, label=-170.222653879),\n",
       " Row(f1=1.0, f2=0.00024, f3=-0.12887, f4=-0.01287, f5=0.18377, f6=-0.07004, f7=0.10632, f8=-0.40884, label=-127.850350049),\n",
       " Row(f1=1.0, f2=6e-05, f3=-0.06767, f4=0.08402, f5=0.14438, f6=-0.19704, f7=0.2839, f8=-0.12487, label=-110.295233798),\n",
       " Row(f1=1.0, f2=5e-05, f3=0.59406, f4=0.25195, f5=-0.00541, f6=-0.05218, f7=0.12202, f8=-0.1285, label=27.7039261796),\n",
       " Row(f1=0.0, f2=-8e-05, f3=-0.08562, f4=-0.00398, f5=-0.17124, f6=-0.13839, f7=-0.23696, f8=-0.814, label=-301.722572842),\n",
       " Row(f1=1.0, f2=-0.0001, f3=-0.28606, f4=-0.00447, f5=-0.10446, f6=-0.25006, f7=-0.03288, f8=-0.87445, label=-361.98704195),\n",
       " Row(f1=0.0, f2=-0.00018, f3=0.02462, f4=0.03503, f5=0.04794, f6=0.00395, f7=0.22638, f8=-0.39012, label=-158.114779137),\n",
       " Row(f1=1.0, f2=0.0001, f3=0.57047, f4=0.09443, f5=-0.0398, f6=-0.19704, f7=-0.36438, f8=-0.13402, label=-21.0376612977)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try it here\n",
    "requests_rdd.map(process_line).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8f5e9811b6a4249e05f0ab6a8e0bf1b0",
     "grade": true,
     "grade_id": "cell-eb7f9c98c6ea4aa7",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "np.testing.assert_equal(len(requests_rdd.map(process_line).first()), 9)\n",
    "np.testing.assert_equal(requests_rdd.map(process_line).count(), 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2:\n",
    "\n",
    "Transform the `requests_rdd` RDD into a Spark 2.0 DataFrame and store it in `requests_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "78c9aae903456dc64119177e49791c86",
     "grade": false,
     "grade_id": "cell-b3baf345ff984885",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create requests_df variable here\n",
    "# YOUR CODE HERE\n",
    "requests_df = requests_rdd.map(process_line).toDF()\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2189b6d7dff14756348efa1026c923ee",
     "grade": true,
     "grade_id": "cell-c24d71122ae35aeb",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "np.testing.assert_equal(type(requests_df), sql.dataframe.DataFrame)\n",
    "np.testing.assert_equal(set(requests_df.columns), {'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'label'})\n",
    "np.testing.assert_equal(requests_df.count(), 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3:\n",
    "\n",
    "In this question, we will explore the data. We have a hypothesis that depending on whether the request was from the \"HOST\" or \"SERVER\" (`f1` column), there are significant difference in the outcome (`label` column).\n",
    "\n",
    "You will find whether this is true by computing two quantities for each group of `f1`. You will compute the mean outcome and the *standard error of the mean* or SE of the outcome. The equation for SE of a variable $x$ is:\n",
    "\n",
    "$$\\text{SE}(x) = \\frac{\\text{std}(x)}{\\sqrt{n}}$$\n",
    "\n",
    "From `requests_df`, create a dataframe `summary_df` that contains, for each value of `f1`, the mean `label` as a column `mlabel` and the SEM of `label` as a column `semlabel`. For the SE equation, use the *sample standard devivation* computed by `fn.stddev_samp`. **Hint: perform an aggregate operation and use appropriate combinations of functions in the package `fn`. Rename columns appropriately**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "5cd64475bf2c5f99796bc209e46bb516",
     "grade": false,
     "grade_id": "cell-15727d5a477764c8",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create the dataframe `summary_df` below\n",
    "# YOUR CODE HERE\n",
    "summary_df = requests_df.groupBy('f1').agg(fn.mean('label').alias('mlabel'),(fn.stddev_samp('label')/(fn.sqrt(fn.count('label')))).alias('semlabel'))\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schema of `summary_df` should look like:\n",
    "\n",
    "```python\n",
    "summary_df.printSchema()\n",
    "```\n",
    "```console\n",
    "root\n",
    " |-- f1: double (nullable = true)\n",
    " |-- mlabel: double (nullable = true)\n",
    " |-- semlabel: double (nullable = true)\n",
    "\n",
    "```\n",
    "The mean label for each `f1` feature should be:\n",
    "\n",
    "```python\n",
    "summary_df.select('f1', 'mlabel').show()\n",
    "```\n",
    "\n",
    "```console\n",
    "+---+------------------+\n",
    "| f1|            mlabel|\n",
    "+---+------------------+\n",
    "|0.0|-29.61175341232892|\n",
    "|1.0|-12.62243193686321|\n",
    "+---+------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d8bdffa782f0329e14ec7490f42027e0",
     "grade": true,
     "grade_id": "cell-fefc94eb4f5a3aab",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 10 pts\n",
    "np.testing.assert_equal(summary_df.count(), 2)\n",
    "np.testing.assert_equal(set(summary_df.columns), {'f1', 'mlabel', 'semlabel'})\n",
    "np.testing.assert_approx_equal(summary_df.rdd.map(lambda r: r.mlabel).sum(), -42.23418534919213,\n",
    "                              significant=3)\n",
    "np.testing.assert_approx_equal(summary_df.rdd.map(lambda r: r.semlabel).sum(), 3.503568410619124,\n",
    "                              significant=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistically, we say that a mean $\\overline{x}$ is *statistically* different from another mean $\\overline{y}$ if it is not within 2 standard errors of the mean of x (i.e., $\\overline{y} \\not\\in \\{\\overline{x} \\pm 2\\text{SE}(x)\\}$). Discuss whether you think the mean label for f1 = 0 is statistically different from the mean label for f1 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+------------------+\n",
      "| f1|             mlabel|          semlabel|\n",
      "+---+-------------------+------------------+\n",
      "|0.0|-29.611753412328927|1.7554606758419875|\n",
      "|1.0| -12.62243193686321|1.7481077347771363|\n",
      "+---+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display it to make your argument\n",
    "summary_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3 pts for your answer below:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "2807d621ff61a9939fab060738f0ed61",
     "grade": true,
     "grade_id": "cell-6a7822206e856e7c",
     "locked": false,
     "points": 3,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "When the sample size is different, we can't compare the two means directly. Statistically, out of two means $\\overline{x}$ and $\\overline{y}$, if $\\overline{y}$ falls in the range of $\\{\\overline{x} \\pm 2\\text{SE}(x)\\}$, than and than only they are equal. In this case, the acceptable range is {-27.855,-31.366}, and $\\overline{y}$ does not fall in this range. Thus, statistically different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4:\n",
    "\n",
    "Use the transformer `VectorAssembler` to create a dataframe that puts all columns `f1`, `f2`, ..., `f8` from `requests_df` into a column named `features`. Assign the vector assembler object into a variable `va` and the new dataframe into the variable  `features_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9b8e718f4d06bf724fb9be5673a5ad75",
     "grade": false,
     "grade_id": "cell-56d045d1b2c78b89",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# this defines a transformer\n",
    "cols = ['f1','f2','f3','f4','f5','f6','f7','f8']\n",
    "va = feature.VectorAssembler(inputCols=cols,outputCol='features')\n",
    "features_df = va.transform(requests_df)\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schema of the new dataframe should be like this:\n",
    "\n",
    "```python\n",
    "features_df.printSchema()\n",
    "```\n",
    "\n",
    "```console\n",
    "root\n",
    " |-- f1: double (nullable = true)\n",
    " |-- f2: double (nullable = true)\n",
    " |-- f3: double (nullable = true)\n",
    " |-- f4: double (nullable = true)\n",
    " |-- f5: double (nullable = true)\n",
    " |-- f6: double (nullable = true)\n",
    " |-- f7: double (nullable = true)\n",
    " |-- f8: double (nullable = true)\n",
    " |-- label: double (nullable = true)\n",
    " |-- features: vector (nullable = true)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------+--------+--------+-------+--------+--------+--------------+--------------------+\n",
      "| f1|     f2|      f3|      f4|      f5|     f6|      f7|      f8|         label|            features|\n",
      "+---+-------+--------+--------+--------+-------+--------+--------+--------------+--------------------+\n",
      "|0.0| 8.0E-5| 0.45592| 0.25362|-0.12878|-0.0693| -0.1474|-0.53736|-106.947151761|[0.0,8.0E-5,0.455...|\n",
      "|0.0|-1.0E-5| 0.10405|-0.17047| 0.10127|0.13776| 0.66619| 0.32221| 127.061566761|[0.0,-1.0E-5,0.10...|\n",
      "|1.0|-1.0E-5|-0.72394| 0.31161| 0.06975| 0.0086|-0.44817|-0.22976|-170.222653879|[1.0,-1.0E-5,-0.7...|\n",
      "+---+-------+--------+--------+--------+-------+--------+--------+--------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try it here\n",
    "features_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e6eb40dd5b5fa05c1023d76f52b65e6a",
     "grade": true,
     "grade_id": "cell-c4cea7728b05e44a",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "np.testing.assert_equal(type(features_df), sql.dataframe.DataFrame)\n",
    "np.testing.assert_equal(set(features_df.columns), \n",
    "                        {'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'features', 'label'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5:\n",
    "\n",
    "Run a linear regression model on `features_df` using the `features` column to predict the `label` column. Store the transformer fit to the data in the `lr_model` variable (the transformer is what the estimator's `fit` function returns). Use the transformer to create a dataframe named `predictions_df` with two columns: `label` and `prediction` based on the `features_df` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4abee269b07e549d04187eb6bb0ec423",
     "grade": false,
     "grade_id": "cell-73fa24e4562cc788",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create the linear regression estimator below and name it lr_model.\n",
    "# use the model to create the dataframe predictions_df with two columns label and prediction\n",
    "# by transforming the dataframe `features_df` \n",
    "# YOUR CODE HERE\n",
    "lr_estimator = regression.LinearRegression(featuresCol='features',labelCol='label')\n",
    "lr_model = lr_estimator.fit(features_df)\n",
    "predictions_df = lr_model.transform(features_df).select('prediction','label')\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting dataframe should be in `predictions_df`. Running `predictions_df.show(5)` should produce something like\n",
    "\n",
    "```python\n",
    "predictions_df.show(5)\n",
    "```\n",
    "\n",
    "```console\n",
    "+--------------+-------------------+\n",
    "|         label|         prediction|\n",
    "+--------------+-------------------+\n",
    "| 163.877101489| 159.06994708337518|\n",
    "|-105.023368852| -99.52598722329135|\n",
    "|-115.011801582|-109.91382979074436|\n",
    "|-122.623452696|-118.62864861627764|\n",
    "|-117.130523174|-116.89245751669506|\n",
    "+--------------+-------------------+\n",
    "only showing top 5 rows\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ec0d6e5bd9c1bd12863c30c7c875c102",
     "grade": true,
     "grade_id": "cell-34b5676f440b3406",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts:\n",
    "np.testing.assert_equal(set(predictions_df.columns), {'label', 'prediction'})\n",
    "np.testing.assert_equal(predictions_df.count(), 10000)\n",
    "np.testing.assert_equal(type(lr_model), regression.LinearRegressionModel)\n",
    "np.testing.assert_equal(type(va), feature.VectorAssembler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The root mean squared error is defined as\n",
    "\n",
    "$$ \\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (\\hat{y}_i - y_i)^2}$$\n",
    "\n",
    "Combine functions in `fn` package and other functions to create a dataframe called `rmse_df` that contains the root mean squared error in column `rmse` based on the `predictions_df` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "fe489899f4801290068db0969c83cd00",
     "grade": false,
     "grade_id": "cell-926f142075117a76",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# define the `rmse_df` dataframe here\n",
    "# YOUR CODE HERE\n",
    "rmse_df = predictions_df.select((fn.col('prediction')-fn.col('label')).alias('Error'))\\\n",
    "            .select(fn.sqrt(fn.avg(fn.col('Error')**2)).alias('rmse'))\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|             rmse|\n",
      "+-----------------+\n",
      "|8.518758143015017|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rmse_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bff0dbd9aa0c52434c23dbd98f75207a",
     "grade": true,
     "grade_id": "cell-8e931520fb661fef",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "np.testing.assert_array_less(rmse_df.first().rmse, 10)\n",
    "np.testing.assert_equal(rmse_df.count(), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Add the constant 10 to each feature in `requests_df` and redo the analytics pipeline from Q5, creating a vector assembler `va2`, `features2_df`, `lr_model2`, and `predictions2_df`. When adding the constant 10, preserve the column names in `features2_df` such that the columns in this new dataframe should be `f1` thorugh `f8`. Do not modify the column `label`. Fit a new linear model, similar to question 4, compute its root mean square error, and store it in `rmse2_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3df1a2ae840d9e9006ee38bdaff58b9a",
     "grade": false,
     "grade_id": "cell-41b0350bc300afd9",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|             rmse|\n",
      "+-----------------+\n",
      "|8.518758149923627|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# below, define `va2`, `features2_df`, `lr_model2`, and `predictions2_df`\n",
    "# YOUR CODE HERE\n",
    "# adding the constant 10 to all the features and storing it in the requests2_df\n",
    "new1 = 10 + fn.col('f1')\n",
    "new2 = 10 + fn.col('f2')\n",
    "new3 = 10 + fn.col('f3')\n",
    "new4 = 10 + fn.col('f4')\n",
    "new5 = 10 + fn.col('f5')\n",
    "new6 = 10 + fn.col('f6')\n",
    "new7 = 10 + fn.col('f7')\n",
    "new8 = 10 + fn.col('f8')\n",
    "\n",
    "requests2_df = requests_df.select(new1.alias('f1'), new2.alias('f2'),new3.alias('f3'), new4.alias('f4'), new5.alias('f5')\\\n",
    "                                  , new6.alias('f6'), new7.alias('f7'), new8.alias('f8'),'label')\n",
    "va2 = feature.VectorAssembler(inputCols=['f1','f2','f3','f4','f5','f6','f7','f8'],\n",
    "                            outputCol='features')\n",
    "features2_df = va2.transform(requests2_df)\n",
    "lr_estimator2 = regression.LinearRegression(featuresCol = 'features',labelCol = 'label')\n",
    "lr_model2 = lr_estimator2.fit(features2_df)\n",
    "predictions2_df = lr_model2.transform(features2_df).select('label','prediction')\n",
    "rmse2_df = predictions2_df.select(fn.sqrt(fn.avg((fn.col('prediction')-fn.col('label'))**2)).alias('rmse'))\n",
    "rmse2_df.show()\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6e0c70ca41096c79a291adcea121caa5",
     "grade": true,
     "grade_id": "cell-c623a7c9d32598ca",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 10 pts:\n",
    "np.testing.assert_equal(set(predictions2_df.columns), {'label', 'prediction'})\n",
    "np.testing.assert_equal(predictions2_df.count(), 10000)\n",
    "np.testing.assert_equal(type(va2), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(lr_model2), regression.LinearRegressionModel)\n",
    "np.testing.assert_array_less(rmse2_df.first().rmse, 10)\n",
    "np.testing.assert_equal(rmse2_df.count(), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the root mean squared error of Q5 and Q6. They should be almost exactly the same. Also, compare the coefficients and intercepts of `lr_model` and `lr_model2`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Q5\n",
      "+-----------------+\n",
      "|             rmse|\n",
      "+-----------------+\n",
      "|8.518758143015017|\n",
      "+-----------------+\n",
      "\n",
      "RMSE Q6\n",
      "+-----------------+\n",
      "|             rmse|\n",
      "+-----------------+\n",
      "|8.518758149923627|\n",
      "+-----------------+\n",
      "\n",
      "intercept lr_model -29.021294776587045\n",
      "intercept lr_model2 -1693217.0787756755\n",
      "coefficients lr_model [18.1193559502,168571.485812,142.743086656,0.0177685997449,0.516398597292,360.134796508,-0.018413421964,228.77831545]\n",
      "coefficients lr_model2 [18.119351094,168568.514405,142.743100906,0.017766615555,0.516449578366,360.134797865,-0.0184312477126,228.778308614]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception happened during processing of request from ('127.0.0.1', 40666)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/opt/conda/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/opt/conda/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/opt/conda/lib/python3.6/socketserver.py\", line 696, in __init__\n",
      "    self.handle()\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 235, in handle\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/usr/local/spark/python/pyspark/serializers.py\", line 685, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE Q5\")\n",
    "rmse_df.show()\n",
    "print(\"RMSE Q6\")\n",
    "rmse2_df.show()\n",
    "print(\"intercept lr_model\", lr_model.intercept)\n",
    "print(\"intercept lr_model2\", lr_model2.intercept)\n",
    "print(\"coefficients lr_model\", lr_model.coefficients)\n",
    "print(\"coefficients lr_model2\", lr_model2.coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5 pts for your answer below:** Comment on why there are differences or similarities between coefficients, intercepts, RMSE, even though we modified the features. You can use [Latex in Markdown](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html#LaTeX-equations) to put some math into your explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b1f7b7efb60b9e493f11a27d67583ec8",
     "grade": true,
     "grade_id": "cell-0318a9e158ee196e",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "For changing the features, we added constants to the feature set. If we plot the new and old features, we will see that there is a constant difference in them. In other words, the intercepts will change as the plot is shifted, but the coefficients and rmsw values will remain the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2 pts for your answer below:** Based on `lr_model2`'s coefficients, give a layman's interpreation of the effect of the source (\"HOST\" or \"SERVER\") on the output variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7bf80f3d2e575e58f0934babcf8434cc",
     "grade": true,
     "grade_id": "cell-6afe3c81e9720bcc",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "In linear Regression, the basic equation we follow is y= a*x+b.\n",
    "\n",
    "\n",
    "\n",
    "The output y is affected by three parameters a(coefficients), x(slope) and b(intercept). \n",
    "\n",
    "\n",
    "\n",
    "For lr_model2, \"b\" = -1693217.0787756755 ; \"a\" are the set of coefficients and \"x\"is the feature value (f_1). A HOST is considered as 1 and SERVER as 0. Because of this, every output for HOST depends on the coefficients, whereas for SERVER it is constant."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
