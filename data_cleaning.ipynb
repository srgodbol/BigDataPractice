{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "64e0c30ad7ac3fe14cd160feb3723062",
     "grade": false,
     "grade_id": "cell-b038e38b5e3072a9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# IST 718: Big Data Analytics\n",
    "\n",
    "- Professor: Daniel Acuna <deacuna@syr.edu>\n",
    "- TAs: Tong Zeng <tozeng@syr.edu>, Priya Matnani <psmatnan@syr.edu>\n",
    "\n",
    "## General instructions:\n",
    "\n",
    "- You are welcome to discuss the problems with your classmates but __you are not allowed to copy any part of your answers either from your classmates or from the internet__\n",
    "- You can put the homework files anywhere you want in your http://notebook.acuna.io workspace but _do not change_ the file names. The TAs and the professor use these names to grade your homework.\n",
    "- Remove or comment out code that contains `raise NotImplementedError`. This is mainly to make the `assert` statement fail if nothing is submitted.\n",
    "- The tests shown in some cells (i.e., `assert` statements) are used to grade your answers. However, the professor and TAs will use __additional__ test for your answer. Think about cases where your code should run even if it passess all the tests you see.\n",
    "- Before downloading and submitting your work through Blackboard, remember to save and press `Validate` (or go to \n",
    "`Kernel`$\\rightarrow$`Restart and Run All`). \n",
    "- Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create spark and sparkcontext objects\n",
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warning: Use exclusively Spark 1.6 when asked to do so and Spark 2.0 (dataframes) only in the last question. Do not use Pandas at all in this assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Data cleaning and basic analyses\n",
    "\n",
    "In this part, you will learn to read data from non-standard formats, clean data, and produce some basic analysis of it.\n",
    "\n",
    "We will use Spark 1.6 (`sparkContext` on variable `sc`) to load text files from which we will extract features that are predictive of a target value. Unfortunately, the data is stored in some non-standard format where each line contains the customer index, the feature index, and the value of the feature for that customer. Similarly, the target files contain in each line the customer index and the target value. We will load these files into two RDDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_features_rdd = sc.textFile('/datasets/features')\n",
    "raw_target_rdd = sc.textFile('/datasets/targets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An issue with the data is that there were problems transmitting the features and targets. If this happened, then a text `ERROR TRANSFERRING` replaced the data. If you look at the first 35 values of the features and target RDD, you will see these types of lines:\n",
    "\n",
    "```python\n",
    "In: raw_features_rdd.take(35)\n",
    "```\n",
    "\n",
    "```bash\n",
    "Out: ['customer(4); feature(0); value(-0.79)',\n",
    " 'customer(4); feature(1); value(-0.28)',\n",
    " 'customer(4); feature(2); value(-0.26)',\n",
    " 'customer(4); feature(3); value(0.28)',\n",
    " 'customer(4); feature(4); value(-0.17)',\n",
    " 'customer(4); feature(5); value(-0.51)',\n",
    " 'customer(4); feature(6); value(0.44)',\n",
    " 'customer(4); feature(7); value(-0.62)',\n",
    " 'customer(4); feature(8); value(1.82)',\n",
    " 'customer(4); feature(9); value(-0.35)',\n",
    " 'customer(14); feature(0); value(0.53)',\n",
    " 'customer(14); feature(1); value(0.49)',\n",
    " 'customer(14); feature(2); value(0.29)',\n",
    " 'customer(14); feature(3); value(0.15)',\n",
    " 'customer(14); feature(4); value(-0.71)',\n",
    " 'customer(14); feature(5); value(0.77)',\n",
    " 'customer(14); feature(6); value(-0.01)',\n",
    " 'customer(14); feature(7); value(0.86)',\n",
    " 'customer(14); feature(8); value(0.19)',\n",
    " 'customer(14); feature(9); value(-0.14)',\n",
    " 'customer(24); feature(0); value(0.35)',\n",
    " 'customer(24); feature(1); value(0.63)',\n",
    " 'customer(24); feature(2); value(0.02)',\n",
    " 'customer(24); feature(3); value(-0.88)',\n",
    " 'customer(24); feature(4); value(0.16)',\n",
    " 'customer(24); feature(5); value(0.78)',\n",
    " 'customer(24); feature(6); value(-0.34)',\n",
    " 'customer(24); feature(7); value(-0.06)',\n",
    " 'customer(24); feature(8); value(1.42)',\n",
    " 'customer(24); feature(9); value(-0.44)',\n",
    " 'customer(34); feature(0); value(-0.88)',\n",
    " 'ERROR TRANSFERRING',\n",
    " 'customer(34); feature(2); value(-0.69)',\n",
    " 'customer(34); feature(3); value(0.62)',\n",
    " 'customer(34); feature(4); value(0.17)']\n",
    "```\n",
    "\n",
    "```python\n",
    "raw_target_rdd.take(35)\n",
    "```\n",
    "\n",
    "```bash\n",
    "['customer(40); target(-157.39)',\n",
    " 'customer(41); target(-122.48)',\n",
    " 'customer(42); target(-35.32)',\n",
    " 'customer(43); target(-117.87)',\n",
    " 'customer(44); target(112.20)',\n",
    " 'customer(45); target(-261.49)',\n",
    " 'customer(46); target(-395.52)',\n",
    " 'customer(47); target(212.63)',\n",
    " 'customer(48); target(-62.85)',\n",
    " 'customer(49); target(-41.15)',\n",
    " 'customer(140); target(-283.10)',\n",
    " 'customer(141); target(249.36)',\n",
    " 'customer(142); target(54.43)',\n",
    " 'customer(143); target(93.60)',\n",
    " 'customer(144); target(91.50)',\n",
    " 'customer(145); target(-140.93)',\n",
    " 'ERROR TRANSFERRING',\n",
    " 'customer(147); target(95.28)',\n",
    " 'customer(148); target(-323.78)',\n",
    " 'customer(149); target(-293.53)',\n",
    " 'customer(240); target(-151.64)',\n",
    " 'customer(241); target(-110.88)',\n",
    " 'customer(242); target(-109.65)',\n",
    " 'customer(243); target(99.77)',\n",
    " 'customer(244); target(-166.56)',\n",
    " 'customer(245); target(-19.04)',\n",
    " 'customer(246); target(47.42)',\n",
    " 'customer(247); target(86.83)',\n",
    " 'customer(248); target(-161.21)',\n",
    " 'customer(249); target(110.41)',\n",
    " 'customer(340); target(-106.21)',\n",
    " 'customer(341); target(203.06)',\n",
    " 'customer(342); target(101.65)',\n",
    " 'customer(343); target(50.91)',\n",
    " 'ERROR TRANSFERRING']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['customer(7); feature(0); value(-0.67)',\n",
       " 'customer(7); feature(1); value(0.00)',\n",
       " 'customer(7); feature(2); value(-0.36)',\n",
       " 'customer(7); feature(3); value(1.44)',\n",
       " 'customer(7); feature(4); value(-0.19)',\n",
       " 'customer(7); feature(5); value(-0.00)',\n",
       " 'customer(7); feature(6); value(0.06)',\n",
       " 'customer(7); feature(7); value(-0.20)',\n",
       " 'customer(7); feature(8); value(0.72)',\n",
       " 'customer(7); feature(9); value(0.71)',\n",
       " 'customer(17); feature(0); value(0.48)',\n",
       " 'customer(17); feature(1); value(-0.34)',\n",
       " 'customer(17); feature(2); value(0.79)',\n",
       " 'customer(17); feature(3); value(0.25)',\n",
       " 'customer(17); feature(4); value(0.20)',\n",
       " 'customer(17); feature(5); value(0.57)',\n",
       " 'customer(17); feature(6); value(0.28)',\n",
       " 'customer(17); feature(7); value(-0.48)',\n",
       " 'customer(17); feature(8); value(0.93)',\n",
       " 'customer(17); feature(9); value(-0.14)',\n",
       " 'customer(27); feature(0); value(0.02)',\n",
       " 'customer(27); feature(1); value(-0.44)',\n",
       " 'customer(27); feature(2); value(-0.55)',\n",
       " 'ERROR TRANSFERRING',\n",
       " 'customer(27); feature(4); value(0.69)',\n",
       " 'customer(27); feature(5); value(-0.62)',\n",
       " 'customer(27); feature(6); value(-0.36)',\n",
       " 'customer(27); feature(7); value(0.59)',\n",
       " 'customer(27); feature(8); value(-0.10)',\n",
       " 'customer(27); feature(9); value(-0.28)',\n",
       " 'customer(37); feature(0); value(-0.32)',\n",
       " 'customer(37); feature(1); value(-1.32)',\n",
       " 'customer(37); feature(2); value(-0.13)',\n",
       " 'customer(37); feature(3); value(1.04)',\n",
       " 'customer(37); feature(4); value(-0.10)']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try it yourself: raw_features_rdd.take(35) and raw_target_rdd.take(35)\n",
    "raw_features_rdd.take(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['customer(70); target(52.69)',\n",
       " 'customer(71); target(-215.71)',\n",
       " 'customer(72); target(125.61)',\n",
       " 'ERROR TRANSFERRING',\n",
       " 'customer(74); target(-147.76)',\n",
       " 'customer(75); target(35.35)',\n",
       " 'customer(76); target(-104.40)',\n",
       " 'customer(77); target(-25.67)',\n",
       " 'customer(78); target(-140.08)',\n",
       " 'customer(79); target(-50.70)',\n",
       " 'customer(170); target(71.78)',\n",
       " 'ERROR TRANSFERRING',\n",
       " 'customer(172); target(-112.59)',\n",
       " 'customer(173); target(-482.54)',\n",
       " 'customer(174); target(-191.87)',\n",
       " 'customer(175); target(-244.78)',\n",
       " 'customer(176); target(396.75)',\n",
       " 'customer(177); target(-19.60)',\n",
       " 'customer(178); target(89.62)',\n",
       " 'ERROR TRANSFERRING',\n",
       " 'customer(270); target(77.86)',\n",
       " 'customer(271); target(177.87)',\n",
       " 'ERROR TRANSFERRING',\n",
       " 'ERROR TRANSFERRING',\n",
       " 'customer(274); target(80.61)',\n",
       " 'customer(275); target(-133.14)',\n",
       " 'customer(276); target(238.34)',\n",
       " 'customer(277); target(89.10)',\n",
       " 'customer(278); target(36.88)',\n",
       " 'customer(279); target(29.02)',\n",
       " 'customer(370); target(-96.34)',\n",
       " 'customer(371); target(-186.29)',\n",
       " 'ERROR TRANSFERRING',\n",
       " 'customer(373); target(330.42)',\n",
       " 'customer(374); target(161.70)']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_target_rdd.take(35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1:\n",
    "\n",
    "Filter out the lines that contain `ERROR TRANSFERRING` and store them in `raw_features2_rdd` and `raw_target2_rdd` respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7258f0792387b2cdd0c4bb92886496ad",
     "grade": false,
     "grade_id": "cell-626aab3709c46ced",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create raw_features2_rdd and raw_targets2_rdd below\n",
    "# YOUR CODE HERE\n",
    "raw_features2_rdd = raw_features_rdd.filter(lambda x: x != 'ERROR TRANSFERRING')\n",
    "raw_target2_rdd = raw_target_rdd.filter(lambda x: x != 'ERROR TRANSFERRING')\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95036\n",
      "8968\n"
     ]
    }
   ],
   "source": [
    "# check that things work\n",
    "print(raw_features2_rdd.count())\n",
    "print(raw_target2_rdd.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "34b858b2a4dae4c0c6569a235758d7e7",
     "grade": true,
     "grade_id": "cell-16fe9b731c74bdb1",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"5 pts: Check that the lines are properly discarded\"\"\"\n",
    "assert raw_features2_rdd.count() == 95036\n",
    "assert raw_target2_rdd.count() == 8968"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2:\n",
    "You will further process `raw_features2_rdd` such that you will create a key-value RDD of the following form: the key is the customer index as an integer and the value is a dictionary whose key is a string `f_0`, `f_1`, ..., `f_9` for feature index 0, 1, ... 9, respetively, and the value is a floating point number of the feature value. \n",
    "\n",
    "Define a function `map_features2` that performs such key-value pair creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1ac97b311e4bedac55e3aee7cf0a78b3",
     "grade": false,
     "grade_id": "cell-6a8bd9ba37f02ccc",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def map_features2(line):\n",
    "    parts = line.split(';')\n",
    "    parts[0] = parts[0].replace('customer(','')\n",
    "    parts[0] = parts[0].replace(')','').strip()\n",
    "    parts[1] = parts[1].replace('feature(','f_')\n",
    "    parts[1] = parts[1].replace(')','').strip()\n",
    "    parts[2] = parts[2].replace('value(','')\n",
    "    parts[2] = parts[2].replace(')','').strip()\n",
    "    maped_rdd = [int(parts[0]),{parts[1]:parts[2]}]\n",
    "    return maped_rdd\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, for the input element:\n",
    "\n",
    "`'customer(4); feature(0); value(-0.79)'`\n",
    "\n",
    "it should generate\n",
    "```python\n",
    "[4, {'f_0': -0.79}]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7, {'f_0': '-0.67'}],\n",
       " [7, {'f_1': '0.00'}],\n",
       " [7, {'f_2': '-0.36'}],\n",
       " [7, {'f_3': '1.44'}],\n",
       " [7, {'f_4': '-0.19'}],\n",
       " [7, {'f_5': '-0.00'}],\n",
       " [7, {'f_6': '0.06'}],\n",
       " [7, {'f_7': '-0.20'}],\n",
       " [7, {'f_8': '0.72'}],\n",
       " [7, {'f_9': '0.71'}]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test it here\n",
    "raw_features2_rdd.\\\n",
    "    map(map_features2).\\\n",
    "    take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d152e2bbb8f36de1ff57cf05b404ff89",
     "grade": true,
     "grade_id": "cell-185fc07f367e8eb6",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"5 pts: Check that the new raw_features2_rdd and raw_target2_rdd RDDs are correct\"\"\"\n",
    "# key is an integer\n",
    "np.testing.assert_equal(type(raw_features2_rdd.map(map_features2).first()[0]), int)\n",
    "# value is a dictionary\n",
    "np.testing.assert_equal(type(raw_features2_rdd.map(map_features2).first()[1]), dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3:\n",
    "\n",
    "You will create a function `map_target2` that will be applied to `raw_target2_rdd`. This function will create key-value pair where the key is the customer index as an integer and the value is the floating point representation of the target. Assign the resulting RDD to `raw_target3_rdd`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f3218ed9ca9df0d993ead5b0071c927b",
     "grade": false,
     "grade_id": "cell-0a9dc80ecf0c1b6a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def map_target2(line):\n",
    "    parts = line.split(';')\n",
    "    parts[0] = parts[0].replace('customer(','')\n",
    "    parts[0] = parts[0].replace(')','').strip()\n",
    "    parts[1] = parts[1].replace('target(','')\n",
    "    parts[1] = parts[1].replace(')','').strip()\n",
    "    maped_rdd = [int(parts[0]),float(parts[1])]\n",
    "    return maped_rdd\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the assignment here\n",
    "raw_target3_rdd = raw_target2_rdd.map(map_target2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sample of results:\n",
    "\n",
    "```python\n",
    "raw_target2_rdd.map(map_target2).take(5)\n",
    "```\n",
    "\n",
    "```console\n",
    "[[40, -157.39],\n",
    " [41, -122.48],\n",
    " [42, -35.32],\n",
    " [43, -117.87],\n",
    " [44, 112.2],\n",
    " [45, -261.49],\n",
    " [46, -395.52],\n",
    " [47, 212.63],\n",
    " [48, -62.85],\n",
    " [49, -41.15]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[70, 52.69], [71, -215.71], [72, 125.61], [74, -147.76], [75, 35.35]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try it yourself\n",
    "raw_target2_rdd.map(map_target2).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7d9428e8c16803bd9a78ecd1c1bc6dbd",
     "grade": true,
     "grade_id": "cell-00147973f05ae1e7",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"5 pts: Check that raw_target3_rdd contains the right values\"\"\"\n",
    "# check types\n",
    "np.testing.assert_equal(type(raw_target3_rdd.keys().first()), int)\n",
    "np.testing.assert_equal(type(raw_target3_rdd.values().first()), float)\n",
    "# the sum of all targets\n",
    "np.testing.assert_approx_equal(raw_target3_rdd.values().sum(), -179351.71, significant=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4:\n",
    "\n",
    "In this question, you will use map reduce to produce an RDD of key-value pairs where the key is the customer index and the value is a dictionairy with all the features and values associated with that customer. Notice that the map part of the map-reduce is already defined by `map_features2` on `raw_features2_rdd`. Therefore, define the proper `reduce_features2` function to produce the desired results. Create a RDD named `raw_features3_rdd` with the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "bf88749fa6073bb62b123416b87783c6",
     "grade": false,
     "grade_id": "cell-c51c5ed026c36cb7",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def reduce_features2(v1, v2):\n",
    "    val = v1.copy()\n",
    "    val.update(v2)\n",
    "    return val\n",
    "    #raise NotImplementedError()\n",
    "# Apply mapreduce to produce the raw_features3_rdd from raw_features2_rdd\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5020,\n",
       " {'f_0': '0.60',\n",
       "  'f_1': '0.07',\n",
       "  'f_2': '0.21',\n",
       "  'f_3': '-0.18',\n",
       "  'f_4': '-0.34',\n",
       "  'f_6': '0.20',\n",
       "  'f_7': '-0.19',\n",
       "  'f_8': '-0.86',\n",
       "  'f_9': '-0.30'})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_features3_rdd = raw_features2_rdd.map(map_features2).reduceByKey(reduce_features2)\n",
    "raw_features3_rdd.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the map reduce should produce the following example result:\n",
    "```python\n",
    "raw_features3_rdd.take(2)\n",
    "```\n",
    "\n",
    "```console\n",
    "[(0,\n",
    "  {'f_0': -0.57,\n",
    "   'f_1': -0.38,\n",
    "   'f_2': 0.0,\n",
    "   'f_3': -0.07,\n",
    "   'f_4': -0.28,\n",
    "   'f_5': -0.79,\n",
    "   'f_7': 0.28,\n",
    "   'f_8': 1.65,\n",
    "   'f_9': 0.57}),\n",
    " (10,\n",
    "  {'f_0': -0.89,\n",
    "   'f_1': 0.3,\n",
    "   'f_2': 0.62,\n",
    "   'f_3': -0.21,\n",
    "   'f_4': -1.02,\n",
    "   'f_5': -0.28,\n",
    "   'f_6': 0.54,\n",
    "   'f_7': 1.83,\n",
    "   'f_8': -0.35,\n",
    "   'f_9': 0.55})]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ed95bb2f5c17ad9f9fd2528d2a551730",
     "grade": true,
     "grade_id": "cell-f74bab4029291e96",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"10 pts: Check that raw_features3_rdd has the correct format and values. There could be hidden tests!\"\"\"\n",
    "# key is an integer\n",
    "np.testing.assert_equal(type(raw_features3_rdd.first()[0]), int)\n",
    "# value is a dictionary\n",
    "np.testing.assert_equal(type(raw_features3_rdd.first()[1]), dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5:\n",
    "\n",
    "Use the different types of joins between `raw_target3_rdd` and `raw_features3_rdd` (`join`, `leftOuterJoin`, `rightOuterJoin`, or `fullOuterJoin`) combined with possible filters to create RDDs with elements of the form\n",
    "\n",
    "`[customer_index, (target, feature_dict)]`\n",
    "\n",
    "where `target` comes from `raw_target3_rdd`, and `feature_dict` is the dictionary with features from `raw_features3_rdd`.\n",
    "\n",
    "Create the following variables containing RDDs:\n",
    "\n",
    "- `rdd1`: data for customers who have all 10 features and a target\n",
    "- `rdd2`: data for customers who have at least one feature and a target\n",
    "- `rdd3`: data for customers who have all 10 features and may or may not have a target\n",
    "- `rdd4`: data for customers who have at least one features and may or may not have a target\n",
    "- `rdd5`: data for customers who may or may not have features and have a target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, for `rdd1`\n",
    "\n",
    "```python\n",
    "rdd1.sortByKey().take(2)\n",
    "```\n",
    "should return\n",
    "```console\n",
    "[(1,\n",
    "  (36.67,\n",
    "   {'f_0': 0.5,\n",
    "    'f_1': 0.8,\n",
    "    'f_2': -0.49,\n",
    "    'f_3': 0.25,\n",
    "    'f_4': 0.37,\n",
    "    'f_5': 0.73,\n",
    "    'f_6': -0.43,\n",
    "    'f_7': 0.89,\n",
    "    'f_8': -1.85,\n",
    "    'f_9': -0.44})),\n",
    " (3,\n",
    "  (-429.54,\n",
    "   {'f_0': 0.14,\n",
    "    'f_1': -0.87,\n",
    "    'f_2': -0.94,\n",
    "    'f_3': 0.09,\n",
    "    'f_4': -0.69,\n",
    "    'f_5': -0.29,\n",
    "    'f_6': -0.45,\n",
    "    'f_7': -0.6,\n",
    "    'f_8': -1.28,\n",
    "    'f_9': -0.38}))]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4d29a7f878d7ef548fe29a78278cbd14",
     "grade": false,
     "grade_id": "cell-225a18b6658c1598",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create rdd1 here\n",
    "# rdd1: data for customers who have all 10 features and a target\n",
    "rdd1 = raw_features3_rdd.filter(lambda x: len(x[1]) == 10).join(raw_target3_rdd.filter(lambda x : len(x) == 2))\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "58f9c9ce00572b6284c2137ee6b4590f",
     "grade": true,
     "grade_id": "cell-47b082a8f8d07296",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"2 pts: Test if `rdd1` has the right data. Remember that there could be hidden tests!\"\"\"\n",
    "# number of elements expected\n",
    "np.testing.assert_equal(rdd1.count(), 5379)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "815d2ace4f683e0bdd84b88c15faa5ff",
     "grade": false,
     "grade_id": "cell-a2227f28ec0590a5",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create rdd2 here\n",
    "# rdd2: data for customers who have at least one feature and a target\n",
    "rdd2 = raw_features3_rdd.filter(lambda x: len(x[1]) > 1).join(raw_target3_rdd.filter(lambda x : len(x) == 2))\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7d7ff517e74713f666d48753b8bc6a19",
     "grade": true,
     "grade_id": "cell-979375379bbb0eed",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"2 pts: Test if `rdd2` has the right data. Remember that there could be hidden tests!\"\"\"\n",
    "# number of elements expected\n",
    "np.testing.assert_equal(rdd2.count(), 8968)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "58f06ba6876f12cbf2c3fa9040340ffa",
     "grade": false,
     "grade_id": "cell-c9f53c707db68eb9",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create rdd3 below\n",
    "# rdd3: data for customers who have all 10 features and may or may not have a target\n",
    "rdd3 = raw_features3_rdd.filter(lambda x: len(x[1]) == 10).leftOuterJoin(raw_target3_rdd.filter(lambda x : len(x) == 1))\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e39e5323372bb787909156624ab1bb0c",
     "grade": true,
     "grade_id": "cell-03fdfe7235c64d3b",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"2 pts: Test if `rdd3` has the right data. Remember that there could be hidden tests!\"\"\"\n",
    "# number of elements expected\n",
    "np.testing.assert_equal(rdd3.count(), 5984)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "38010d7227348e9121fc89ae66dc5888",
     "grade": false,
     "grade_id": "cell-377795217a758dd1",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create rdd4 here\n",
    "# rdd4: data for customers who have at least one features and may or may not have a target\n",
    "rdd4 = raw_features3_rdd.filter(lambda x: len(x[1]) > 1).leftOuterJoin(raw_target3_rdd.filter(lambda x : len(x) == 1))\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7a25f0832c0cfa7ed975ff00b0cdf8ce",
     "grade": true,
     "grade_id": "cell-0626f1c0620e2bf2",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"2 pts: Test if `rdd4` has the right data. Remember that there could be hidden tests!\"\"\"\n",
    "# number of elements expected\n",
    "np.testing.assert_equal(rdd4.count(), 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "2bc8fdfca520fd589d5ccf8dd915f569",
     "grade": false,
     "grade_id": "cell-0cf6bfcb93ea31c5",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create rdd5 here\n",
    "# rdd5: data for customers who may or may not have features and have a target\n",
    "rdd5 = raw_features3_rdd.filter(lambda x: len(x[1]) > 1).rightOuterJoin(raw_target3_rdd.filter(lambda x : len(x) == 2))\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f2e59fa110c4719d16d7ad021cbb0d1f",
     "grade": true,
     "grade_id": "cell-6523ed798f220d0b",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"2 pts: Test if `rdd5` has the right data. Remember that there could be hidden tests!\"\"\"\n",
    "# number of elements expected\n",
    "np.testing.assert_equal(rdd5.count(), 8968)\n",
    "# elements with no targets\n",
    "np.testing.assert_equal(rdd5.values().filter(lambda x: x[0] is None).count(), 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6:\n",
    "\n",
    "The preprocessed Parquet file for customers who had only ten features and a target present is available in `/datasets/feats_target.parquet`. We will load it into a variable `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet('/datasets/feats_target.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the dataframe a bit:\n",
    "\n",
    "```python\n",
    "df.show(5)\n",
    "```\n",
    "\n",
    "```console\n",
    "+--------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
    "|customer_index|  f_0|  f_1|  f_2|  f_3|  f_4|  f_5|  f_6|  f_7|  f_8|  f_9| target|\n",
    "+--------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
    "|          5135|-0.34|-0.66|-0.11|-0.07|-0.14| 0.03|-0.71|-0.18| -0.4|  0.2|-271.22|\n",
    "|          5235| 0.58|-0.69| 0.59| 0.69|  0.4| 0.65|-0.59|-0.78|-0.56|-0.14|-103.82|\n",
    "|          5335|-0.13|  0.1|-0.13| 0.66|-1.06| -0.9|-0.26| 0.65|-0.08| -0.4|-287.26|\n",
    "|          5435|-0.45| 0.15| 0.39|-0.65| -0.4| 0.38|-0.25| 0.57| 0.33|-0.01|-114.26|\n",
    "|          5635|-0.85|-0.22|-0.51|  0.4| 0.31|-0.79| 0.17| 0.91| -0.6|-0.12|  44.81|\n",
    "+--------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
    "only showing top 5 rows\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
      "|customer_index|  f_0|  f_1|  f_2|  f_3|  f_4|  f_5|  f_6|  f_7|  f_8|  f_9| target|\n",
      "+--------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
      "|          5135|-0.34|-0.66|-0.11|-0.07|-0.14| 0.03|-0.71|-0.18| -0.4|  0.2|-271.22|\n",
      "|          5235| 0.58|-0.69| 0.59| 0.69|  0.4| 0.65|-0.59|-0.78|-0.56|-0.14|-103.82|\n",
      "|          5335|-0.13|  0.1|-0.13| 0.66|-1.06| -0.9|-0.26| 0.65|-0.08| -0.4|-287.26|\n",
      "|          5435|-0.45| 0.15| 0.39|-0.65| -0.4| 0.38|-0.25| 0.57| 0.33|-0.01|-114.26|\n",
      "|          5635|-0.85|-0.22|-0.51|  0.4| 0.31|-0.79| 0.17| 0.91| -0.6|-0.12|  44.81|\n",
      "+--------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# explore it yourself\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subpackage `pyspark.ml.functions` (aliased as `fn` below) contains many common functions for data analysis. Find the function for computing the __correlation__ (the strength of the linear relationship between two variables) between two columns, the function for computing __absolute__ values, and create a data frame `correlations_df` that contains the following columns in the following order:\n",
    "\n",
    "1. `c0_target`: correlation between feature 0 and target\n",
    "1. `c1_target`: correlation between feature 1 and target\n",
    "1. `c2_target`: correlation between feature 2 and target\n",
    "1. `c3_target`: correlation between feature 3 and target\n",
    "1. `c4_target`: correlation between feature 4 and target\n",
    "1. `c5_target`: correlation between feature 5 and target\n",
    "1. `c6_target`: correlation between feature 6 and target\n",
    "1. `c7_target`: correlation between feature 7 and target\n",
    "1. `c8_target`: correlation between feature 8 and target\n",
    "1. `c9_target`: correlation between feature 9 and target\n",
    "1. `sig0`: boolean `true` if the absolute value of the correlation between feature 0 and target is greater than 0.5, `false` o.w.\n",
    "1. `sig1`: boolean `true` if the absolute value of the correlation between feature 1 and target is greater than 0.5, `false` o.w.\n",
    "1. `sig2`: boolean `true` if the absolute value of the correlation between feature 2 and target is greater than 0.5, `false` o.w.\n",
    "1. `sig3`: boolean `true` if the absolute value of the correlation between feature 3 and target is greater than 0.5, `false` o.w.\n",
    "1. `sig4`: boolean `true` if the absolute value of the correlation between feature 4 and target is greater than 0.5, `false` o.w.\n",
    "1. `sig5`: boolean `true` if the absolute value of the correlation between feature 5 and target is greater than 0.5, `false` o.w.\n",
    "1. `sig6`: boolean `true` if the absolute value of the correlation between feature 6 and target is greater than 0.5, `false` o.w.\n",
    "1. `sig7`: boolean `true` if the absolute value of the correlation between feature 7 and target is greater than 0.5, `false` o.w.\n",
    "1. `sig8`: boolean `true` if the absolute value of the correlation between feature 8 and target is greater than 0.5, `false` o.w.\n",
    "1. `sig9`: boolean `true` if the absolute value of the correlation between feature 9 and target is greater than 0.5, `false` o.w.\n",
    "\n",
    "**Hint: Remember that you can pass a list of columns to `df.select`. You can create such list with list comprehension, saving a lot of code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the package functions as fn\n",
    "from pyspark.sql import functions as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|(target + 1)|\n",
      "+------------+\n",
      "|     -270.22|\n",
      "|     -102.82|\n",
      "|     -286.26|\n",
      "|     -113.26|\n",
      "|       45.81|\n",
      "|      -41.24|\n",
      "|      250.34|\n",
      "|      313.92|\n",
      "|      267.92|\n",
      "|      -18.14|\n",
      "+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# apply some function to the columns: df.select(...)\n",
    "df.select(1 + fn.col('target')).show(10)\n",
    "f_Cols= df.columns[1:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d50d7ffa26caed36ab9594774d715b63",
     "grade": false,
     "grade_id": "cell-12e8f5f6de39ae69",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-------------------+--------------------+------------------+--------------------+------------------+-------------------+--------------------+--------------------+-----+----+-----+-----+----+-----+----+-----+-----+-----+\n",
      "|           c0_target|         c1_target|          c2_target|           c3_target|         c4_target|           c5_target|         c6_target|          c7_target|           c8_target|           c9_target| sig0|sig1| sig2| sig3|sig4| sig5|sig6| sig7| sig8| sig9|\n",
      "+--------------------+------------------+-------------------+--------------------+------------------+--------------------+------------------+-------------------+--------------------+--------------------+-----+----+-----+-----+----+-----+----+-----+-----+-----+\n",
      "|0.004550467203235565|0.5175418076531231|0.24222549922181658|-0.02725292295686...|0.6109343603342663|-0.01506188705709...|0.5763480950714736|0.06334859042481801|0.007563889344988309|-0.01715842226040...|false|true|false|false|true|false|true|false|false|false|\n",
      "+--------------------+------------------+-------------------+--------------------+------------------+--------------------+------------------+-------------------+--------------------+--------------------+-----+----+-----+-----+----+-----+----+-----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the dataframe `correlations_df` here\n",
    "cor_df = df.select([fn.corr(x,'target').alias('c'+ x.split('_')[1]+'_target') for x in f_Cols])\n",
    "sig_df = df.select([fn.when(fn.abs(fn.corr(x,'target'))>0.5, True).otherwise(False).alias('sig'+ x.split('_')[1]) for x in f_Cols])\n",
    "cor_df= cor_df.withColumn(\"join_id\", fn.monotonically_increasing_id())\n",
    "sig_df= sig_df.withColumn(\"join_id\", fn.monotonically_increasing_id())\n",
    "correlations_df= cor_df.join(sig_df,\"join_id\",\"outer\").drop(\"join_id\")\n",
    "correlations_df.show()\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f96f79c9bf6897cb69f4a9269a4a0017",
     "grade": true,
     "grade_id": "cell-ea3814c44cba8dcc",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"10 pts: Check that the dataframe has the correct columns and values. There could be hidden tests!\"\"\"\n",
    "# check column names\n",
    "column_names = ['c' + str(fi) + '_target' for fi in range(10)] + \\\n",
    "               ['sig' + str(fi) for fi in range(10)]\n",
    "\n",
    "# column's names and positions in the right order\n",
    "np.testing.assert_equal(correlations_df.columns, column_names)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
